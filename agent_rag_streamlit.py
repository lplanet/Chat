"""
Interface Streamlit pour l'agent RAG avec openai-agents.
Lance avec: streamlit run agent_rag_streamlit.py
"""

import streamlit as st
import os
from dotenv import load_dotenv
from agents import Agent, Runner, function_tool
from upstash_vector import Index

# Charger les variables d'environnement
load_dotenv()

# Configuration de la page
st.set_page_config(
    page_title="Agent RAG - Portfolio Leslie Planet",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Appliquer le style du portfolio
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700;800;900&display=swap');
    
    /* Style global */
    * {
        font-family: 'Poppins', sans-serif;
    }
    
    /* ArriÃ¨re-plan et couleurs principales */
    .stApp {
        background: #F8F5CD;
    }
    
    /* Titres */
    h1, h2, h3 {
        color: #ce52a9 !important;
        font-family: 'Poppins', sans-serif;
    }
    
    /* Messages de chat */
    .stChatMessage {
        background-color: #ffe6f8 !important;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
    }
    
    /* Zone de saisie */
    .stChatInputContainer {
        background-color: #ffe6f8;
        border-radius: 8px;
    }
    
    /* Boutons */
    .stButton > button {
        background: #00abf0;
        color: #F8F5CD;
        border: 2px solid #00abf0;
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
        font-family: 'Poppins', sans-serif;
    }
    
    .stButton > button:hover {
        background: #F8F5CD;
        color: #00abf0;
        border: 2px solid #00abf0;
    }
    
    /* Sidebar */
    [data-testid="stSidebar"] {
        background-color: #ffe6f8;
    }
    
    [data-testid="stSidebar"] h1, 
    [data-testid="stSidebar"] h2, 
    [data-testid="stSidebar"] h3 {
        color: #ce52a9 !important;
    }
    
    [data-testid="stSidebar"] p {
        color: #0B1b29;
    }
    
    /* MÃ©triques */
    [data-testid="stMetricValue"] {
        color: #ce52a9;
    }
    
    /* Expander */
    .streamlit-expanderHeader {
        background-color: #ffe6f8;
        color: #ce52a9;
        border-radius: 8px;
    }
    
    /* Spinner */
    .stSpinner > div {
        border-top-color: #00abf0 !important;
    }
    
    /* Input text */
    .stTextInput > div > div > input {
        background-color: white;
        color: #0B1b29;
        border: 2px solid #00abf0;
        border-radius: 8px;
    }
    
    /* Messages texte */
    p, li {
        color: #0B1b29;
    }
    
    /* Liens */
    a {
        color: #00abf0;
        text-decoration: none;
        transition: color 0.3s ease;
    }
    
    a:hover {
        color: #ce52a9;
    }
    
    /* Markdown en gÃ©nÃ©ral */
    .stMarkdown {
        color: #0B1b29;
    }
    
    /* Colonnes */
    [data-testid="column"] {
        background: transparent;
    }
</style>
""", unsafe_allow_html=True)

# Initialiser Upstash Vector
@st.cache_resource
def init_upstash():
    return Index(
        url=os.getenv("UPSTASH_VECTOR_REST_URL"),
        token=os.getenv("UPSTASH_VECTOR_REST_TOKEN")
    )

upstash_index = init_upstash()


@function_tool
def search_portfolio(query: str, top_k: int = 3) -> str:
    """
    Recherche des informations dans le portfolio de Leslie Planet.
    
    Args:
        query: La question ou le sujet Ã  rechercher
        top_k: Nombre de documents Ã  retourner
        
    Returns:
        Documents pertinents formatÃ©s
    """
    try:
        results = upstash_index.query(
            data=query,
            top_k=top_k,
            include_metadata=True,
            include_data=True
        )
        
        if not results:
            return "Aucun document pertinent trouvÃ©."
        
        formatted_results = []
        for i, result in enumerate(results, 1):
            metadata = result.metadata if hasattr(result, 'metadata') else {}
            data = result.data if hasattr(result, 'data') else ""
            source = metadata.get('source', 'Unknown')
            
            formatted_results.append(
                f"Document {i} (Source: {source}):\n{data}\n"
            )
        
        return "\n---\n".join(formatted_results)
        
    except Exception as e:
        return f"Erreur: {str(e)}"


@st.cache_resource
def create_agent():
    """CrÃ©e l'agent RAG."""
    return Agent(
        name="portfolio-assistant",
        instructions="""Tu es un assistant IA spÃ©cialisÃ© dans le portfolio de Leslie Planet.

Utilise la fonction search_portfolio pour rechercher des informations et base tes rÃ©ponses 
UNIQUEMENT sur les rÃ©sultats trouvÃ©s. RÃ©ponds de maniÃ¨re concise et professionnelle en franÃ§ais.""",
        model="gpt-4.1-nano",
        tools=[search_portfolio],
    )

agent = create_agent()

# Interface Streamlit
st.title("ğŸ¤– Agent RAG - Portfolio Leslie Planet")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("â„¹ï¸ Ã€ propos")
    st.markdown("""
    Cet agent utilise **RAG (Retrieval Augmented Generation)** :
    
    1. ğŸ” **Recherche** dans Upstash Vector
    2. ğŸ“„ **RÃ©cupÃ¨re** les documents pertinents
    3. ğŸ¤– **GÃ©nÃ¨re** une rÃ©ponse avec GPT
    
    **Technologies :**
    - openai-agents
    - Upstash Vector
    - GPT-4o-mini
    - Streamlit
    """)
    
    st.markdown("---")
    
    # Stats
    try:
        info = upstash_index.info()
        st.metric("ğŸ“Š Documents indexÃ©s", info.vector_count)
    except:
        pass
    
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ Effacer l'historique"):
        st.session_state.messages = []
        st.rerun()

# Initialiser l'historique
if "messages" not in st.session_state:
    st.session_state.messages = []

# Initialiser la question sÃ©lectionnÃ©e
if "selected_question" not in st.session_state:
    st.session_state.selected_question = None

# Initialiser le flag pour cacher les suggestions
if "hide_suggestions" not in st.session_state:
    st.session_state.hide_suggestions = False

# Afficher l'historique
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Fonction pour traiter une question
def process_question(question: str):
    """Traite une question et gÃ©nÃ¨re la rÃ©ponse."""
    # Cacher les suggestions aprÃ¨s avoir cliquÃ©
    st.session_state.hide_suggestions = True
    
    # Ajouter le message utilisateur s'il n'est pas dÃ©jÃ  dans l'historique
    if not st.session_state.messages or st.session_state.messages[-1]["content"] != question:
        st.session_state.messages.append({"role": "user", "content": question})
    
    # Afficher le message utilisateur
    with st.chat_message("user"):
        st.markdown(question)
    
    # Obtenir la rÃ©ponse de l'agent
    with st.chat_message("assistant"):
        with st.spinner("ğŸ”„ RÃ©flexion en cours..."):
            try:
                result = Runner.run_sync(agent, question)
                response = result.final_output
                st.markdown(response)
                
                # Afficher les Ã©tapes (optionnel)
                if hasattr(result, 'events') and result.events:
                    with st.expander("ğŸ“‹ Voir les Ã©tapes de raisonnement"):
                        for event in result.events:
                            if hasattr(event, 'type'):
                                st.text(f"- {event.type}")
                
            except Exception as e:
                response = f"âŒ Erreur: {e}"
                st.error(response)
    
    # Ajouter la rÃ©ponse Ã  l'historique
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    # RÃ©initialiser la question sÃ©lectionnÃ©e
    st.session_state.selected_question = None

# Input utilisateur avec gestion de la question sÃ©lectionnÃ©e
if st.session_state.selected_question:
    # Traiter la question sÃ©lectionnÃ©e
    process_question(st.session_state.selected_question)
    st.rerun()

# Afficher les suggestions UNIQUEMENT si l'historique est vide et qu'elles ne sont pas cachÃ©es
# Utiliser un container pour les positionner juste avant le chat_input
if not st.session_state.messages and not st.session_state.hide_suggestions:
    suggestions_container = st.container()
    with suggestions_container:
        st.markdown("### ğŸ’¡ Questions suggÃ©rÃ©es")
        col1, col2 = st.columns(2)
        
        suggestions = [
            ("ğŸ‘¤ Qui est Leslie ?", "Qui est Leslie Planet ?"),
            ("ğŸ› ï¸ CompÃ©tences Python", "Quelles sont ses compÃ©tences en Python ?"),
            ("ğŸ’¼ Projets", "Parle-moi de ses projets"),
            ("ğŸ¢ Stage IMA", "Quelle est son expÃ©rience chez IMA ?")
        ]
        
        for i, (label, question) in enumerate(suggestions):
            col = col1 if i % 2 == 0 else col2
            with col:
                if st.button(label, key=f"btn_{i}"):
                    st.session_state.selected_question = question
                    st.rerun()

# Le chat_input doit Ãªtre appelÃ© en dernier pour apparaÃ®tre en bas
prompt = st.chat_input("Posez votre question...")
if prompt:
    process_question(prompt)
    st.rerun()
