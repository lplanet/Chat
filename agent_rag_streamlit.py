"""
Interface Streamlit pour l'agent RAG avec openai-agents.
Lance avec: streamlit run agent_rag_streamlit.py
"""

import streamlit as st
import os
from dotenv import load_dotenv
from agents import Agent, Runner, function_tool
from upstash_vector import Index

# Charger les variables d'environnement
load_dotenv()

# Configuration de la page
st.set_page_config(
    page_title="Agent RAG - Portfolio Leslie Planet",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Initialiser Upstash Vector
@st.cache_resource
def init_upstash():
    return Index(
        url=os.getenv("UPSTASH_VECTOR_REST_URL"),
        token=os.getenv("UPSTASH_VECTOR_REST_TOKEN")
    )

upstash_index = init_upstash()


@function_tool
def search_portfolio(query: str, top_k: int = 3) -> str:
    """
    Recherche des informations dans le portfolio de Leslie Planet.
    
    Args:
        query: La question ou le sujet Ã  rechercher
        top_k: Nombre de documents Ã  retourner
        
    Returns:
        Documents pertinents formatÃ©s
    """
    try:
        results = upstash_index.query(
            data=query,
            top_k=top_k,
            include_metadata=True,
            include_data=True
        )
        
        if not results:
            return "Aucun document pertinent trouvÃ©."
        
        formatted_results = []
        for i, result in enumerate(results, 1):
            metadata = result.metadata if hasattr(result, 'metadata') else {}
            data = result.data if hasattr(result, 'data') else ""
            source = metadata.get('source', 'Unknown')
            
            formatted_results.append(
                f"Document {i} (Source: {source}):\n{data}\n"
            )
        
        return "\n---\n".join(formatted_results)
        
    except Exception as e:
        return f"Erreur: {str(e)}"


@st.cache_resource
def create_agent():
    """CrÃ©e l'agent RAG."""
    return Agent(
        name="portfolio-assistant",
        instructions="""Tu es un assistant IA spÃ©cialisÃ© dans le portfolio de Leslie Planet.

Utilise la fonction search_portfolio pour rechercher des informations et base tes rÃ©ponses 
UNIQUEMENT sur les rÃ©sultats trouvÃ©s. RÃ©ponds de maniÃ¨re concise et professionnelle en franÃ§ais.""",
        model="gpt-4.1-nano",
        tools=[search_portfolio],
    )

agent = create_agent()

# Interface Streamlit
st.title("ğŸ¤– Agent RAG - Portfolio Leslie Planet")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("â„¹ï¸ Ã€ propos")
    st.markdown("""
    Cet agent utilise **RAG (Retrieval Augmented Generation)** :
    
    1. ğŸ” **Recherche** dans Upstash Vector
    2. ğŸ“„ **RÃ©cupÃ¨re** les documents pertinents
    3. ğŸ¤– **GÃ©nÃ¨re** une rÃ©ponse avec GPT
    
    **Technologies :**
    - openai-agents
    - Upstash Vector
    - GPT-4o-mini
    - Streamlit
    """)
    
    st.markdown("---")
    
    # Stats
    try:
        info = upstash_index.info()
        st.metric("ğŸ“Š Documents indexÃ©s", info.vector_count)
    except:
        pass
    
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ Effacer l'historique"):
        st.session_state.messages = []
        st.rerun()

# Initialiser l'historique
if "messages" not in st.session_state:
    st.session_state.messages = []

# Afficher l'historique
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input utilisateur
if prompt := st.chat_input("Posez votre question..."):
    # Ajouter le message utilisateur
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Obtenir la rÃ©ponse de l'agent
    with st.chat_message("assistant"):
        with st.spinner("ğŸ”„ RÃ©flexion en cours..."):
            try:
                result = Runner.run_sync(agent, prompt)
                response = result.final_output
                st.markdown(response)
                
                # Afficher les Ã©tapes (optionnel)
                if hasattr(result, 'events') and result.events:
                    with st.expander("ğŸ“‹ Voir les Ã©tapes de raisonnement"):
                        for event in result.events:
                            if hasattr(event, 'type'):
                                st.text(f"- {event.type}")
                
            except Exception as e:
                response = f"âŒ Erreur: {e}"
                st.error(response)
    
    # Ajouter la rÃ©ponse Ã  l'historique
    st.session_state.messages.append({"role": "assistant", "content": response})

# Suggestions
if not st.session_state.messages:
    st.markdown("### ğŸ’¡ Questions suggÃ©rÃ©es")
    col1, col2 = st.columns(2)
    
    suggestions = [
        ("ğŸ‘¤ Qui est Leslie ?", "Qui est Leslie Planet ?"),
        ("ğŸ› ï¸ CompÃ©tences Python", "Quelles sont ses compÃ©tences en Python ?"),
        ("ğŸ’¼ Projets", "Parle-moi de ses projets"),
        ("ğŸ¢ Stage IMA", "Quelle est son expÃ©rience chez IMA ?")
    ]
    
    for i, (label, question) in enumerate(suggestions):
        col = col1 if i % 2 == 0 else col2
        with col:
            if st.button(label, key=f"btn_{i}"):
                st.session_state.messages.append({"role": "user", "content": question})
                st.rerun()
